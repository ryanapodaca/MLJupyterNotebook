{"cells":[{"attachments":{},"cell_type":"markdown","metadata":{},"source":["# ANN From Scratch\n","\n","This file is a companion to chapter 17 of Deep Learning for Coders with Fastai and PyTorch."]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["#These are just initializations for now.\n","weights = [1,1,1] #Per connection\n","inputs = [1,1,1,] #Per input\n","output = None\n","bias = 1\n","x = None #The number of inputs, sub i\n","w = None #The number of weights, sub i "]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["output = sum([x*w for x,w in zip(inputs, weights)])+bias \n","\n","print(output)\n","\n","#x and w are used to iterate over the vector to output its dot product. "]},{"attachments":{},"cell_type":"markdown","metadata":{},"source":["The zip() method in Python is used to combine two or more arrays into a single iterable object, called a \"zip object\". Each element of the zip object contains the corresponding elements from each of the input arrays."]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["#example of zip\n","a = [1, 2, 3]\n","b = [4, -5, 6]\n","\n","zipped = zip(a, b)\n","\n","print(list(zipped))\n","print(sum([x*w for x,w in zip(a,b)]))"]},{"attachments":{},"cell_type":"markdown","metadata":{},"source":["The preceding code can be formally represented  as:\n","\n","For perceptrons:\n","$$output = \\sum_{i=1}^{n} x_iw_i+b$$\n","\n","For a layer:\n","$$y_i,_j = \\sum_{k=1}^{n} x_i,_k*w_i,_j+b_j$$\n","\n","LaTeX notation"]},{"attachments":{},"cell_type":"markdown","metadata":{},"source":["<!-- <span style=\"font-family: Georgia\"> -->\n","cGPT: The above code computes the weighted sum of two input sequences input and weight. The zip() function combines the corresponding elements of the two sequences into pairs, and the for loop iterates over these pairs.\n","\n","During each iteration of the loop, the variable x represents an element from input, and the variable w represents the corresponding weight from weight. The expression x*w computes the product of the element and its weight, and the list comprehension collects these products into a new list.\n","Finally, the built-in sum() function computes the sum of the elements in the new list, which is the weighted sum of the two input sequences.\n","\n","Note that both input and weight should have the same length for this code to work correctly."]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["def rectifiedLinearUnit(x):\n","    return x if x >= 0 else 0"]},{"attachments":{},"cell_type":"markdown","metadata":{},"source":["*Hidden Size*\n","\n","Refers to size of inputs in hidden layers\n","\n","*Dense Layer*\n","\n","Refers to a layer that is fully connected, also referred to as a linear layer. "]},{"attachments":{},"cell_type":"markdown","metadata":{},"source":["By virtue of linear algebra, many dot products occur when doing matrix multiplication. \n","\n","If our inputs are a matrix x with a batch size of *n* inputs, and if we have grouped them together with weights *w* of *n* neurons by *n* inputs(*n* is the same), and also add the biases of a vector *b* with size *n* neurons, then the output of the connected network will be:\n","\n","$$y_i,_j = \\sum_{k=1}^{n} x_i,_kw_i,_j+b_j$$"]},{"attachments":{},"cell_type":"markdown","metadata":{},"source":["![circle ANN](./img/circleANN.png)"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["#Through code.\n","y = None\n","i = None\n","j = None\n","\n","\n","y[i,j] = sum([x*w for x,w in zip(x[i,:],w[j,:])])+b[j]"]}],"metadata":{"language_info":{"name":"python"},"orig_nbformat":4},"nbformat":4,"nbformat_minor":2}
